{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 14:16:01.847529: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from imutils.perspective import four_point_transform\n",
    "from skimage.segmentation import clear_border\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "from skimage.morphology import remove_small_objects\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from tensorflow.keras import backend as K\n",
    "from scipy.ndimage import center_of_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = 'Photos/20200829_192717.png'\n",
    "# image = 'Photos/whiteout.png'\n",
    "# image = 'Photos/Screenshot 2020-09-09 at 17.34.16.png'\n",
    "im = cv2.imread(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_img(im, figsize=(5,5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(im, cmap='gray')\n",
    "\n",
    "def crop_img(img, scale=1.0):\n",
    "    center_x, center_y = img.shape[1] / 2, img.shape[0] / 2\n",
    "    width_scaled, height_scaled = img.shape[1] * scale, img.shape[0] * scale\n",
    "    left_x, right_x = center_x - width_scaled / 2, center_x + width_scaled / 2\n",
    "    top_y, bottom_y = center_y - height_scaled / 2, center_y + height_scaled / 2\n",
    "    img_cropped = img[int(top_y):int(bottom_y), int(left_x):int(right_x)]\n",
    "    return img_cropped\n",
    "\n",
    "def find_puzzle(image, debug=False):\n",
    "    # convert the image to grayscale and blur it slightly\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (21, 21), 4)\n",
    "        # apply adaptive thresholding and then invert the threshold map\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blurred, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "    )\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "    # check to see if we are visualizing each step of the image\n",
    "    # processing pipeline (in this case, thresholding)\n",
    "    if debug: \n",
    "        print_img(thresh)\n",
    "    dilated = cv2.dilate(thresh, kernel = np.ones((1,1),np.uint8), iterations=4)\n",
    "    if debug: \n",
    "        print_img(dilated)\n",
    "    cnts = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "    # initialize a contour that corresponds to the puzzle outline\n",
    "    puzzleCnt = []\n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "        # approximate the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        # if our approximated contour has four points, then we can\n",
    "        # assume we have found the outline of the puzzle\n",
    "        if len(approx) == 4:\n",
    "            puzzleCnt.append(approx)\n",
    "            break\n",
    "        # if the puzzle contour is empty then our script could not find\n",
    "    if puzzleCnt is None:\n",
    "        raise Exception((\"Could not find Slitherlinker puzzle outline. \"\n",
    "            \"Try debugging your thresholding and contour steps.\"))\n",
    "    # check to see if we are visualizing the outline of the detected\n",
    "    # Sudoku puzzle\n",
    "    if debug:\n",
    "        # draw the contour of the puzzle on the image and then display\n",
    "        # it to our screen for visualization/debugging purposes\n",
    "        output = image.copy()\n",
    "        cv2.drawContours(output, puzzleCnt, -1, (0, 255, 0), 2)\n",
    "        print_img(output)\n",
    "    puzzle = four_point_transform(image, puzzleCnt[0].reshape(4, 2))\n",
    "    warped = four_point_transform(gray, puzzleCnt[0].reshape(4, 2))\n",
    "    if debug:\n",
    "        print_img(warped)\n",
    "    return puzzle, warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle, warped = find_puzzle(im, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "# print_img(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blurred = cv2.GaussianBlur(gray, (15,15), 4)\n",
    "# # blurred = cv2.blur(gray, (15, 15), 3)\n",
    "#     # apply adaptive thresholding and then invert the threshold map\n",
    "# print_img(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "# print_img(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh = cv2.bitwise_not(thresh)\n",
    "# print_img(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dilated = cv2.dilate(thresh, kernel = np.ones((1,1),np.uint8), iterations=4)\n",
    "# print_img(dilated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnts = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cnts = imutils.grab_contours(cnts)\n",
    "# cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_contours = im.copy()\n",
    "# cv2.drawContours(all_contours, cnts, -1, (0, 255, 0), 2)\n",
    "# print_img(all_contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize a contour that corresponds to the puzzle outline\n",
    "# puzzleCnt = []\n",
    "# # loop over the contours\n",
    "# for c in cnts:\n",
    "#     # approximate the contour\n",
    "#     peri = cv2.arcLength(c, True)\n",
    "#     approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "#     # if our approximated contour has four points, then we can\n",
    "#     # assume we have found the outline of the puzzle\n",
    "#     if len(approx) == 4:\n",
    "#         puzzleCnt.append(approx)\n",
    "#         break\n",
    "# len(puzzleCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = im.copy()\n",
    "# cv2.drawContours(output, puzzleCnt, -1, (0, 255, 0), 2)\n",
    "# print_img(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puzzle = four_point_transform(im, puzzleCnt[0].reshape(4, 2))\n",
    "# warped = four_point_transform(gray, puzzleCnt[0].reshape(4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle = crop_img(puzzle, 0.93)\n",
    "warped = crop_img(warped, 0.93)\n",
    "print_img(puzzle, figsize=(5,5))\n",
    "print_img(warped, figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(warped.shape)\n",
    "w, h = warped.shape\n",
    "cell_w, cell_h = int(w / 6), int(h / 6)\n",
    "min_size = int(cell_w * cell_h * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "fig, axs = plt.subplots(6,6, figsize=(10,10))\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        sub_img = warped[cell_w * i :cell_w * (i + 1), cell_h * j: cell_h * (j + 1)]\n",
    "        cleaned = remove_small_objects(~(sub_img > 128), min_size=(cell_w * cell_h * 0.01))\n",
    "#         cleaned = sub_img > 128\n",
    "#         cleaned = clear_border(cleaned)\n",
    "        if np.sum(cleaned) > 0:\n",
    "            axs[i,j].imshow(cleaned)\n",
    "            indices.append((i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_4_classes(x, y):\n",
    "    res_x, res_y = [], []\n",
    "    for x, y in zip(x, y):\n",
    "        if y < 4:\n",
    "            res_x.append(x)\n",
    "            res_y.append(y)\n",
    "    return np.array(res_x), np.array(res_y)\n",
    "    \n",
    "def translate_to_com(im, com):\n",
    "    x_trans = int(im.shape[0]//2-com[0])\n",
    "    y_trans = int(im.shape[1]//2-com[1])\n",
    "\n",
    "    # Pad and remove pixels from image to perform translation\n",
    "\n",
    "    if x_trans > 0:\n",
    "        im2 = np.pad(im, ((x_trans, 0), (0, 0)), mode='constant')\n",
    "        im2 = im2[:im.shape[0]-x_trans, :]\n",
    "    else:\n",
    "        im2 = np.pad(im, ((0, -x_trans), (0, 0)), mode='constant')\n",
    "        im2 = im2[-x_trans:, :]\n",
    "\n",
    "    if y_trans > 0:\n",
    "        im3 = np.pad(im2, ((0, 0), (y_trans, 0)), mode='constant')\n",
    "        im3 = im3[:, :im.shape[0]-y_trans]\n",
    "\n",
    "    else:\n",
    "        im3 = np.pad(im2, ((0, 0), (0, -y_trans)), mode='constant')\n",
    "        im3 = im3[:, -y_trans:]\n",
    "        \n",
    "    return im3\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 4\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "#     brightness_range=(0.8, 1.4),\n",
    "    zoom_range=(0.8, 1.6),\n",
    "    shear_range=0.3,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.1,\n",
    "#     horizontal_flip=True\n",
    ")\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False and os.path.exists('model.hd5'):\n",
    "    model = keras.models.load_model('model.hd5')\n",
    "else:\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    x_train, y_train = reduce_to_4_classes(x_train, y_train)\n",
    "    x_test, y_test = reduce_to_4_classes(x_test, y_test)\n",
    "    \n",
    "    # Scale images to the [0, 1] range\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_test = x_test.astype(\"float32\") / 255\n",
    "    # Make sure images have shape (28, 28, 1)\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "    print(\"x_train shape:\", x_train.shape)\n",
    "    print(x_train.shape[0], \"train samples\")\n",
    "    print(x_test.shape[0], \"test samples\")\n",
    "    # convert class vectors to binary class matrices\n",
    "    \n",
    "    y_train = keras.utils.to_categorical(y_train, 4)\n",
    "    y_test = keras.utils.to_categorical(y_test, 4)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", f1_m])\n",
    "\n",
    "    batch_size = 8\n",
    "    epochs = 60\n",
    "    \n",
    "    model.fit(datagen.flow(x_train, y_train, batch_size=batch_size), validation_data=(x_test, y_test), epochs=epochs,\n",
    "              callbacks=[keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True,)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6,6, figsize=(10, 10))\n",
    "for i, j in indices:\n",
    "    offset_x = 0\n",
    "    offset_y = 0\n",
    "    sub_img = warped[offset_x + cell_w * i: offset_x + cell_w * (i +1), offset_y + cell_h * j: offset_y + cell_h * (j + 1)]\n",
    "    sub_img = cv2.GaussianBlur(sub_img, (11, 11), 2)\n",
    "    sub_img = ~(sub_img > 128)\n",
    "\n",
    "    sub_img = remove_small_objects(sub_img, min_size=(cell_w * cell_h * 0.01)) * 255\n",
    "    com = center_of_mass(sub_img)\n",
    "    sub_img = translate_to_com(sub_img, com)\n",
    "    sub_img = cv2.resize(sub_img.astype(np.uint8), dsize=(28,28))\n",
    "    \n",
    "    sub_img = sub_img.reshape(input_shape)\n",
    "    axs[i][j].imshow(sub_img / 255.)\n",
    "    pred_vector = model.predict(np.array([sub_img > 0]))[0]\n",
    "    prediction = np.argmax(pred_vector)\n",
    "    print(f'Prediction ({i,j}): {prediction} ({pred_vector[prediction]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
